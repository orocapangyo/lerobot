# 데이터셋 사용법

## 개요

이 문서에서는 LeRobotDataset을 실전에서 활용하는 다양한 방법을 다룹니다.

---

## Hub에서 데이터셋 다운로드

### 기본 다운로드

```python
from lerobot.datasets import LeRobotDataset

# HuggingFace Hub에서 자동 다운로드
dataset = LeRobotDataset("lerobot/pusht")

# 캐시 위치 확인
print(f"데이터셋 위치: {dataset.root}")
# 기본값: ~/.cache/huggingface/lerobot/
```

### 특정 위치에 다운로드

```python
# 커스텀 캐시 디렉토리
dataset = LeRobotDataset(
    "lerobot/pusht",
    root="/path/to/my/datasets"
)
```

### 데이터셋 버전 지정

```python
# 특정 리비전(버전) 사용
dataset = LeRobotDataset(
    "lerobot/pusht",
    revision="v2.0"  # 특정 버전
)

# 또는 커밋 해시
dataset = LeRobotDataset(
    "lerobot/pusht",
    revision="abc123def"
)
```

---

## 사용 가능한 데이터셋 확인

### 전체 데이터셋 목록

```python
from lerobot import available_datasets

print(f"총 {len(available_datasets)}개 데이터셋")

# 처음 20개 출력
for dataset_id in list(available_datasets)[:20]:
    print(f"  - {dataset_id}")
```

### 데이터셋 필터링

```python
# 특정 로봇의 데이터셋만
aloha_datasets = [
    ds for ds in available_datasets
    if "aloha" in ds.lower()
]

print(f"ALOHA 데이터셋: {len(aloha_datasets)}개")
for ds in aloha_datasets:
    print(f"  - {ds}")

# 특정 작업의 데이터셋
pusht_datasets = [
    ds for ds in available_datasets
    if "pusht" in ds.lower()
]
```

### Hub에서 검색

```python
from huggingface_hub import list_datasets

# HuggingFace Hub에서 lerobot 관련 데이터셋 검색
datasets = list_datasets(
    author="lerobot",
    limit=100
)

for ds in datasets:
    print(f"{ds.id}: {ds.downloads} downloads")
```

---

## 에피소드 선택 및 필터링

### 특정 에피소드만 로드

```python
# 에피소드 0-9만 사용
dataset = LeRobotDataset(
    "lerobot/pusht",
    episodes=list(range(10))
)

print(f"로드된 에피소드: {dataset.num_episodes}")
print(f"총 프레임: {len(dataset)}")
```

### 에피소드 범위 지정

```python
# 에피소드 100-199
dataset = LeRobotDataset(
    "lerobot/pusht",
    episodes=list(range(100, 200))
)
```

### 랜덤 에피소드 샘플링

```python
import random

# 전체 에피소드 수 확인
full_dataset = LeRobotDataset("lerobot/pusht")
total_episodes = full_dataset.num_episodes

# 랜덤하게 50개 에피소드 선택
random_episodes = random.sample(range(total_episodes), 50)

dataset = LeRobotDataset(
    "lerobot/pusht",
    episodes=random_episodes
)
```

### 조건부 필터링

```python
# 성공한 에피소드만 (메타데이터에 success 정보가 있는 경우)
dataset = LeRobotDataset("lerobot/aloha_insertion")

successful_episodes = []
for ep_idx in range(dataset.num_episodes):
    # 에피소드 메타데이터 확인
    ep_data = dataset.meta.episodes[ep_idx]
    if ep_data.get("success", False):
        successful_episodes.append(ep_idx)

# 성공한 에피소드만으로 새 데이터셋
filtered_dataset = LeRobotDataset(
    "lerobot/aloha_insertion",
    episodes=successful_episodes
)

print(f"전체: {dataset.num_episodes}, 성공: {len(successful_episodes)}")
```

---

## 훈련/검증/테스트 분할

### 기본 분할

```python
from lerobot.datasets import LeRobotDataset

# 전체 데이터셋 로드
full_dataset = LeRobotDataset("lerobot/pusht")
total_episodes = full_dataset.num_episodes

# 80/10/10 분할
train_size = int(0.8 * total_episodes)
val_size = int(0.1 * total_episodes)

train_episodes = list(range(0, train_size))
val_episodes = list(range(train_size, train_size + val_size))
test_episodes = list(range(train_size + val_size, total_episodes))

# 각 분할로 데이터셋 생성
train_dataset = LeRobotDataset("lerobot/pusht", episodes=train_episodes)
val_dataset = LeRobotDataset("lerobot/pusht", episodes=val_episodes)
test_dataset = LeRobotDataset("lerobot/pusht", episodes=test_episodes)

print(f"Train: {len(train_dataset)} frames, {len(train_episodes)} episodes")
print(f"Val: {len(val_dataset)} frames, {len(val_episodes)} episodes")
print(f"Test: {len(test_dataset)} frames, {len(test_episodes)} episodes")
```

### 랜덤 분할

```python
import random

# 에피소드 인덱스 랜덤 셔플
all_episodes = list(range(total_episodes))
random.shuffle(all_episodes)

# 분할
train_episodes = all_episodes[:train_size]
val_episodes = all_episodes[train_size:train_size + val_size]
test_episodes = all_episodes[train_size + val_size:]

train_dataset = LeRobotDataset("lerobot/pusht", episodes=train_episodes)
val_dataset = LeRobotDataset("lerobot/pusht", episodes=val_episodes)
test_dataset = LeRobotDataset("lerobot/pusht", episodes=test_episodes)
```

### Stratified 분할

```python
from sklearn.model_selection import train_test_split

# 작업별로 분할 (여러 작업이 있는 데이터셋의 경우)
dataset = LeRobotDataset("lerobot/aloha_mixed")

# 각 에피소드의 작업 추출
tasks = [dataset.meta.episodes[i]["task"] for i in range(dataset.num_episodes)]

# Stratified split
train_idx, test_idx = train_test_split(
    range(dataset.num_episodes),
    test_size=0.2,
    stratify=tasks,
    random_state=42
)

train_idx, val_idx = train_test_split(
    train_idx,
    test_size=0.125,  # 0.1 of total
    stratify=[tasks[i] for i in train_idx],
    random_state=42
)

train_dataset = LeRobotDataset("lerobot/aloha_mixed", episodes=train_idx)
val_dataset = LeRobotDataset("lerobot/aloha_mixed", episodes=val_idx)
test_dataset = LeRobotDataset("lerobot/aloha_mixed", episodes=test_idx)
```

---

## DataLoader와 함께 사용

### 기본 DataLoader

```python
import torch
from torch.utils.data import DataLoader

dataset = LeRobotDataset("lerobot/pusht")

dataloader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,
    pin_memory=True,  # GPU 사용시
    drop_last=True,   # 마지막 불완전한 배치 제거
)

# 훈련 루프
for batch_idx, batch in enumerate(dataloader):
    images = batch["observation.image"]  # (B, C, H, W)
    states = batch["observation.state"]  # (B, state_dim)
    actions = batch["action"]            # (B, action_dim)

    # 모델 훈련...

    if batch_idx == 0:
        print(f"배치 shape:")
        print(f"  이미지: {images.shape}")
        print(f"  상태: {states.shape}")
        print(f"  액션: {actions.shape}")
        break
```

### 에피소드 인식 샘플러

에피소드 경계를 넘지 않도록 샘플링:

```python
from lerobot.datasets.sampler import EpisodeAwareSampler

dataset = LeRobotDataset("lerobot/pusht")

# 에피소드 경계를 고려하는 샘플러
sampler = EpisodeAwareSampler(
    episode_data_index=dataset.episode_data_index,
    shuffle=True,
    drop_last=True
)

dataloader = DataLoader(
    dataset,
    batch_size=32,
    sampler=sampler,
    num_workers=4,
)
```

### 분산 학습용 샘플러

```python
from torch.utils.data.distributed import DistributedSampler

# Multi-GPU 훈련시
sampler = DistributedSampler(
    dataset,
    num_replicas=world_size,
    rank=rank,
    shuffle=True
)

dataloader = DataLoader(
    dataset,
    batch_size=32,
    sampler=sampler,
    num_workers=4,
)
```

---

## 델타 타임스탬프 활용

### 시계열 데이터 로드

```python
# 과거 2프레임, 현재, 미래 1프레임의 관측
dataset = LeRobotDataset(
    "lerobot/pusht",
    delta_timestamps={
        "observation.image": [-2, -1, 0, 1],
        "observation.state": [-2, -1, 0, 1],
        "action": [0],  # 현재 액션만
    }
)

frame = dataset[100]

# 4개 프레임의 이미지 (과거2, 과거1, 현재, 미래1)
print(frame["observation.image"].shape)  # (4, C, H, W)

# 4개 프레임의 상태
print(frame["observation.state"].shape)  # (4, state_dim)

# 현재 액션
print(frame["action"].shape)  # (action_dim,)
```

### Action Chunking

```python
# ACT 스타일: 100 스텝 action chunk
dataset = LeRobotDataset(
    "lerobot/aloha_insertion",
    delta_timestamps={
        "observation.images.cam_high": [0],
        "observation.images.cam_left_wrist": [0],
        "observation.images.cam_right_wrist": [0],
        "observation.state": [0],
        "action": list(range(100)),  # 0~99 스텝
    }
)

frame = dataset[0]
print(frame["action"].shape)  # (100, action_dim)
```

### 비대칭 시계열

```python
# 관측은 과거 포함, 액션은 미래 포함
dataset = LeRobotDataset(
    "lerobot/pusht",
    delta_timestamps={
        "observation.image": [-3, -2, -1, 0],  # 과거 3프레임 + 현재
        "observation.state": [-1, 0],          # 과거 1프레임 + 현재
        "action": [0, 1, 2, 3, 4],            # 현재 + 미래 4프레임
    }
)
```

---

## 멀티 데이터셋 사용

### 데이터셋 결합

```python
from lerobot.datasets import MultiLeRobotDataset

# 여러 데이터셋 결합
multi_dataset = MultiLeRobotDataset([
    "lerobot/pusht",
    "lerobot/pusht_image_aug",
    "my_username/my_pusht_data"
])

print(f"결합된 데이터셋:")
print(f"  총 프레임: {len(multi_dataset)}")
print(f"  데이터셋 수: {len(multi_dataset.datasets)}")

# 각 데이터셋 정보
for i, ds in enumerate(multi_dataset.datasets):
    print(f"  Dataset {i}: {len(ds)} frames")
```

### 가중치 샘플링

```python
from torch.utils.data import WeightedRandomSampler

# 데이터셋별로 다른 샘플링 비율
dataset_weights = {
    "lerobot/pusht": 1.0,
    "lerobot/pusht_image_aug": 0.5,
    "my_username/my_pusht_data": 2.0,
}

# 각 프레임의 가중치 계산
weights = []
for ds_idx, ds in enumerate(multi_dataset.datasets):
    ds_weight = list(dataset_weights.values())[ds_idx]
    weights.extend([ds_weight] * len(ds))

sampler = WeightedRandomSampler(
    weights,
    num_samples=len(multi_dataset),
    replacement=True
)

dataloader = DataLoader(
    multi_dataset,
    batch_size=32,
    sampler=sampler
)
```

---

## 데이터 전처리

### 정규화

```python
# 자동 정규화 (stats 사용)
dataset = LeRobotDataset("lerobot/pusht")

frame = dataset[0]

# 이미지: [0, 1] 범위로 자동 정규화됨
print(f"이미지 범위: [{frame['observation.image'].min():.2f}, {frame['observation.image'].max():.2f}]")

# 상태/액션: 평균 0, 표준편차 1로 정규화됨 (stats 기반)
print(f"상태 평균: {frame['observation.state'].mean():.2f}")
print(f"액션 평균: {frame['action'].mean():.2f}")
```

### 역정규화

```python
# 모델 출력을 원래 스케일로 복원
normalized_action = frame["action"]  # 정규화된 액션

# 통계 가져오기
action_mean = dataset.stats["action"]["mean"]
action_std = dataset.stats["action"]["std"]

# 역정규화
denormalized_action = normalized_action * action_std + action_mean

print(f"정규화된 액션: {normalized_action}")
print(f"원래 액션: {denormalized_action}")
```

---

## 메모리 최적화

### 스트리밍 데이터셋

대용량 데이터셋을 메모리에 모두 로드하지 않고 스트리밍:

```python
from lerobot.datasets import StreamingLeRobotDataset

# 스트리밍 모드
streaming_dataset = StreamingLeRobotDataset(
    "lerobot/large_dataset",
    streaming=True
)

# 일반 데이터셋처럼 사용 가능
dataloader = DataLoader(streaming_dataset, batch_size=32)
```

### 비디오 캐싱 비활성화

```python
# 비디오를 매번 디코딩 (메모리 절약)
dataset = LeRobotDataset(
    "lerobot/pusht",
    video_backend="pyav",  # 빠른 디코딩
    cache_videos=False     # 캐싱 비활성화
)
```

### 선택적 키 로드

```python
# 필요한 키만 로드하여 메모리 절약
# (현재 LeRobotDataset은 전체 로드하지만, 커스텀 collate_fn으로 가능)

def custom_collate_fn(batch):
    """필요한 키만 추출"""
    return {
        "observation.state": torch.stack([b["observation.state"] for b in batch]),
        "action": torch.stack([b["action"] for b in batch]),
        # 이미지는 제외
    }

dataloader = DataLoader(
    dataset,
    batch_size=32,
    collate_fn=custom_collate_fn
)
```

---

## 데이터 증강

### 이미지 증강

```python
from lerobot.datasets.transforms import ImageTransforms

# 증강 설정
transforms = ImageTransforms(
    brightness=0.2,      # ±20% 밝기
    contrast=0.2,        # ±20% 대비
    saturation=0.2,      # ±20% 채도
    hue=0.1,            # ±10% 색조
    sharpness=0.5,      # ±50% 선명도
    max_crop_percent=0.1,  # 최대 10% 크롭
)

dataset = LeRobotDataset(
    "lerobot/pusht",
    image_transforms=transforms
)

# 증강된 이미지 확인
frame = dataset[0]
print(frame["observation.image"].shape)
```

### 훈련/평가 시 다른 증강

```python
# 훈련용: 증강 O
train_transforms = ImageTransforms(brightness=0.2, contrast=0.2)
train_dataset = LeRobotDataset(
    "lerobot/pusht",
    episodes=train_episodes,
    image_transforms=train_transforms
)

# 평가용: 증강 X
val_dataset = LeRobotDataset(
    "lerobot/pusht",
    episodes=val_episodes,
    image_transforms=None  # 증강 없음
)
```

---

## 데이터 검증

### 데이터 무결성 확인

```python
import torch

def validate_dataset(dataset, num_samples=100):
    """데이터셋 검증"""
    print(f"데이터셋 검증 시작... (샘플: {num_samples})")

    errors = []

    for i in range(min(num_samples, len(dataset))):
        try:
            frame = dataset[i]

            # 이미지 검증
            if "observation.image" in frame:
                img = frame["observation.image"]
                if img.min() < 0 or img.max() > 1:
                    errors.append(f"프레임 {i}: 이미지 범위 오류 [{img.min()}, {img.max()}]")
                if torch.isnan(img).any():
                    errors.append(f"프레임 {i}: 이미지에 NaN")

            # 액션 검증
            action = frame["action"]
            if torch.isnan(action).any():
                errors.append(f"프레임 {i}: 액션에 NaN")
            if torch.isinf(action).any():
                errors.append(f"프레임 {i}: 액션에 Inf")

        except Exception as e:
            errors.append(f"프레임 {i}: {str(e)}")

        if i % 20 == 0:
            print(f"  {i}/{num_samples} 검증 완료")

    if errors:
        print(f"\n⚠️  {len(errors)}개 오류 발견:")
        for err in errors[:10]:  # 처음 10개만
            print(f"  - {err}")
    else:
        print("✓ 데이터셋 검증 성공!")

    return len(errors) == 0

# 검증 실행
dataset = LeRobotDataset("lerobot/pusht")
validate_dataset(dataset)
```

---

## 고급 활용

### 커스텀 데이터 로더

```python
class CustomDataLoader:
    """에피소드 단위로 로드하는 커스텀 로더"""

    def __init__(self, dataset, batch_size=32):
        self.dataset = dataset
        self.batch_size = batch_size

    def __iter__(self):
        # 에피소드별로 반복
        for ep_idx in range(self.dataset.num_episodes):
            start = self.dataset.episode_data_index["from"][ep_idx]
            end = self.dataset.episode_data_index["to"][ep_idx]

            # 에피소드의 모든 프레임
            episode_frames = []
            for i in range(start, end):
                episode_frames.append(self.dataset[i])

            # 배치로 나누기
            for i in range(0, len(episode_frames), self.batch_size):
                batch = episode_frames[i:i + self.batch_size]
                yield self._collate(batch)

    def _collate(self, batch):
        """배치 생성"""
        return {
            key: torch.stack([b[key] for b in batch])
            for key in batch[0].keys()
        }

# 사용
loader = CustomDataLoader(dataset, batch_size=32)
for batch in loader:
    print(batch["action"].shape)
    break
```

---

## 다음 단계

- [데이터셋 생성과 관리](12-데이터셋-생성-관리.md) - 자신만의 데이터셋 만들기
- [데이터 변환과 증강](13-데이터-변환-증강.md) - 고급 전처리 기법
- [첫 번째 모델 훈련](../04-tutorials/60-첫-모델-훈련.md) - 데이터셋으로 훈련하기

---

**참조 파일:**
- [src/lerobot/datasets/lerobot_dataset.py](../../../src/lerobot/datasets/lerobot_dataset.py)
- [src/lerobot/datasets/sampler.py](../../../src/lerobot/datasets/sampler.py)
- [examples/dataset/load_lerobot_dataset.py](../../../examples/dataset/load_lerobot_dataset.py)
- [examples/training/train_with_streaming.py](../../../examples/training/train_with_streaming.py)
